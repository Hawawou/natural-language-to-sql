{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oumar/Projects/venv/lib64/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"b-mc2/sql-create-context\", split=\"train\")\n",
    "\n",
    "# split the dataset into training, validation and test\n",
    "dataset_test = dataset.train_test_split(test_size=0.2) \n",
    "\n",
    "# split the dataset into training and validation\n",
    "dataset = dataset_test['train'].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'SELECT power FROM table_name_28 WHERE model = \"2.0 tdi (cr) dpf\" AND years = \"2010–2011\"',\n",
       " 'question': 'What is the power for model  2.0 tdi (cr) dpf, and a Years of 2010–2011?',\n",
       " 'context': 'CREATE TABLE table_name_28 (power VARCHAR, model VARCHAR, years VARCHAR)'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral 7b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/56574 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 56574/56574 [00:07<00:00, 8074.68 examples/s]\n",
      "Map: 100%|██████████| 6287/6287 [00:01<00:00, 6208.36 examples/s]\n",
      "Map: 100%|██████████| 15716/15716 [00:02<00:00, 6377.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# forma data \n",
    "system_message = \"\"\"You are a natural language to sql query translator model. Users will ask you a question in English and you will generate a SQL query based on the table provided: {table}\"\"\"\n",
    "\n",
    "def format_data(dataset):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_message.format(table=dataset[\"context\"])},\n",
    "            {\"role\": \"user\", \"content\": dataset[\"question\"]},\n",
    "            {\"role\": \"assistant\", \"content\": dataset[\"answer\"]}\n",
    "        ]}\n",
    "\n",
    "\n",
    "train_data = dataset['train'].map(format_data)\n",
    "val_data = dataset['test'].map(format_data)\n",
    "test_data = dataset_test['test'].map(format_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'You are a natural language to sql query translator model. Users will ask you a question in English and you will generate a SQL query based on the table provided: CREATE TABLE table_name_28 (power VARCHAR, model VARCHAR, years VARCHAR)',\n",
       "  'role': 'system'},\n",
       " {'content': 'What is the power for model  2.0 tdi (cr) dpf, and a Years of 2010–2011?',\n",
       "  'role': 'user'},\n",
       " {'content': 'SELECT power FROM table_name_28 WHERE model = \"2.0 tdi (cr) dpf\" AND years = \"2010–2011\"',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data = train_data.map(lambda x: {\"schema\": format_schema(x[\"table\"])})\n",
    "train_data[\"messages\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train_data)\n",
    "df2 = pd.DataFrame(val_data)\n",
    "df3 = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': \"You are a natural language to sql query translator model. Users will ask you a question in English and you will generate a SQL query based on the table provided: {'header': ['State/territory', 'Text/background colour', 'Format', 'Current slogan', 'Current series', 'Notes'], 'page_title': '', 'page_id': '', 'types': ['text', 'text', 'text', 'text', 'text', 'text'], 'id': '1-1000181-1', 'section_title': '', 'caption': '', 'rows': [['Australian Capital Territory', 'blue/white', 'Yaa·nna', 'ACT · CELEBRATION OF A CENTURY 2013', 'YIL·00A', 'Slogan screenprinted on plate'], ['New South Wales', 'black/yellow', 'aa·nn·aa', 'NEW SOUTH WALES', 'BX·99·HI', 'No slogan on current series'], ['New South Wales', 'black/white', 'aaa·nna', 'NSW', 'CPX·12A', 'Optional white slimline series'], ['Northern Territory', 'ochre/white', 'Ca·nn·aa', 'NT · OUTBACK AUSTRALIA', 'CB·06·ZZ', 'New series began in June 2011'], ['Queensland', 'maroon/white', 'nnn·aaa', 'QUEENSLAND · SUNSHINE STATE', '999·TLG', 'Slogan embossed on plate'], ['South Australia', 'black/white', 'Snnn·aaa', 'SOUTH AUSTRALIA', 'S000·AZD', 'No slogan on current series'], ['Victoria', 'blue/white', 'aaa·nnn', 'VICTORIA - THE PLACE TO BE', 'ZZZ·562', 'Current series will be exhausted this year']], 'name': 'table_1000181_1'}\",\n",
       "   'role': 'system'},\n",
       "  {'content': 'Tell me what the notes are for South Australia ',\n",
       "   'role': 'user'},\n",
       "  {'content': 'SELECT Notes FROM table WHERE Current slogan = SOUTH AUSTRALIA',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = df[[\"messages\"]]\n",
    "val_data = df2[[\"messages\"]]\n",
    "test_data = df3[[\"messages\"]]\n",
    "\n",
    "# convert to Dataset\n",
    "from datasets import Dataset\n",
    "train_data = Dataset.from_pandas(train_data)\n",
    "val_data = Dataset.from_pandas(val_data)\n",
    "test_data = Dataset.from_pandas(test_data)\n",
    "\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def open_json(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'content': \"You are a natural language to sql query translator model. Users will ask you a question in English and you will generate a SQL query based on the table provided: {'header': ['State/territory', 'Text/background colour', 'Format', 'Current slogan', 'Current series', 'Notes'], 'page_title': '', 'page_id': '', 'types': ['text', 'text', 'text', 'text', 'text', 'text'], 'id': '1-1000181-1', 'section_title': '', 'caption': '', 'rows': [['Australian Capital Territory', 'blue/white', 'Yaa·nna', 'ACT · CELEBRATION OF A CENTURY 2013', 'YIL·00A', 'Slogan screenprinted on plate'], ['New South Wales', 'black/yellow', 'aa·nn·aa', 'NEW SOUTH WALES', 'BX·99·HI', 'No slogan on current series'], ['New South Wales', 'black/white', 'aaa·nna', 'NSW', 'CPX·12A', 'Optional white slimline series'], ['Northern Territory', 'ochre/white', 'Ca·nn·aa', 'NT · OUTBACK AUSTRALIA', 'CB·06·ZZ', 'New series began in June 2011'], ['Queensland', 'maroon/white', 'nnn·aaa', 'QUEENSLAND · SUNSHINE STATE', '999·TLG', 'Slogan embossed on plate'], ['South Australia', 'black/white', 'Snnn·aaa', 'SOUTH AUSTRALIA', 'S000·AZD', 'No slogan on current series'], ['Victoria', 'blue/white', 'aaa·nnn', 'VICTORIA - THE PLACE TO BE', 'ZZZ·562', 'Current series will be exhausted this year']], 'name': 'table_1000181_1'}\", 'role': 'system'}, {'content': 'Tell me what the notes are for South Australia ', 'role': 'user'}, {'content': 'SELECT Notes FROM table WHERE Current slogan = SOUTH AUSTRALIA', 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "train_data = open_json(\"train_data.jsonl\")\n",
    "val_data = open_json(\"val_data.jsonl\")\n",
    "test_data = open_json(\"test_data.jsonl\")\n",
    "print(json.loads(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AdamW, BitsAndBytesConfig, get_scheduler, DataCollatorWithPadding, AutoModelForSeq2SeqLM\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "import torch\n",
    "from accelerate import Accelerator, init_empty_weights, infer_auto_device_map\n",
    "\n",
    "# enable distributed training\n",
    "accelerate = Accelerator()\n",
    "\n",
    "checkpoint = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "# OOV token\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
    "\n",
    "# padding side\n",
    "tokenizer.pad_padding_side = \"right\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "device_map = {\"\":0}\n",
    "\n",
    "with init_empty_weights():\n",
    "    model = AutoModelForCausalLM.from_pretrained(checkpoint, quantization_config=bnb_config, device_map={\"\":0})\n",
    "# device_map = infer_auto_device_map(model, max_memory={\"cuda\": \"2GiB\", \"cpu\": \"16GiB\"}) \n",
    "# model = model.to(device_map)\n",
    "model = get_peft_model(model, bnb_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient checkpointing\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lora config\n",
    "lora_config = LoraConfig(\n",
    "    r = 256,\n",
    "    lora_alpha=128,\n",
    "    target_modules=\"all-linear\",\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = model.state_dict().keys()\n",
    "for name in layers:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def tokenize_function(dataset):\n",
    "    return tokenizer(dataset[\"messages\"], return_tensors=\"pt\")\n",
    "\n",
    "train_data = train_data.map(tokenize_function, batched=True)\n",
    "val_data = val_data.map(tokenize_function, batched=True)\n",
    "test_data = test_data.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=8, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=8, shuffle=False)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "raw_datasets[\"train\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 50\n",
    "num_train_steps = len(train_data) * num_epochs\n",
    "\n",
    "train_dataloader, val_dataloader, model, optimizer = accelerate.prepare(train_dataloader, val_dataloader, model, optimizer)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_train_steps,\n",
    "    gradient_accumulation_steps=4\n",
    ")\n",
    "\n",
    "progress_bar = tqdm(range(num_train_steps))\n",
    "\n",
    "model.train()\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device_map) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "# save model\n",
    "model.save_pretrained(\"natural_language_to_sql\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "model_predict = \"natural_langauge_to_sql\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_predict, torch_dtype=torch.float16)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
